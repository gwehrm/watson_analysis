{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network\n",
    "\n",
    "In this Notebook I will train a Recurrent Neural Network (RNN) on the articles of my watson data set. Then I let the RNN write a new article. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import LineSentence\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "import ipynb\n",
    "import ipynb.fs.full.Classifier as cl#from https://github.com/ptnplanet/NLTK-Contributions/blob/master/ClassifierBasedGermanTagger/ClassifierBasedGermanTagger.py\n",
    "import random\n",
    "import pickle\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>nmbr_comments</th>\n",
       "      <th>themes</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tourismus-Professor pendelt mit Flugzeug zur A...</td>\n",
       "      <td>no_author</td>\n",
       "      <td>28.03.19, 22:15 28.03.19, 22:40</td>\n",
       "      <td>19</td>\n",
       "      <td>['Schweiz', 'Gesellschaft &amp; Politik', 'Klima']</td>\n",
       "      <td>['Naaa, wie kommt ihr so zur Uni? Mit dem Fahr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_title</td>\n",
       "      <td>no_author</td>\n",
       "      <td>no_date</td>\n",
       "      <td>no_comments</td>\n",
       "      <td>[]</td>\n",
       "      <td>['\\r\\n\\t\\tMit deiner Anmeldung erklärst du dic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anstatt mit Bus und Zug fahren mehr Menschen m...</td>\n",
       "      <td>no_author</td>\n",
       "      <td>28.03.19, 17:39</td>\n",
       "      <td>29</td>\n",
       "      <td>['Schweiz', 'Gesellschaft &amp; Politik', 'Mobilit...</td>\n",
       "      <td>['\\nDer Ausbau des öffentlichen Verkehrs würde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Über 80'000 Franken bei Online-Bank N26 geklau...</td>\n",
       "      <td>no_author</td>\n",
       "      <td>28.03.19, 17:34</td>\n",
       "      <td>18</td>\n",
       "      <td>['Digital', 'Schweiz', 'Datenschutz', 'Deutsch...</td>\n",
       "      <td>['\\nDie gefeierte Online-Bank N26 verspielt ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Der Wolf ist zurück – was auch Städter wissen ...</td>\n",
       "      <td>no_author</td>\n",
       "      <td>28.03.19, 16:19</td>\n",
       "      <td>45</td>\n",
       "      <td>['Schweiz', 'Wissen', 'Aargau', 'Natur', 'Tier']</td>\n",
       "      <td>['\\nDer gesetzliche Schutz des Wolfes wird der...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     author  \\\n",
       "0  Tourismus-Professor pendelt mit Flugzeug zur A...  no_author   \n",
       "1                                           no_title  no_author   \n",
       "2  Anstatt mit Bus und Zug fahren mehr Menschen m...  no_author   \n",
       "3  Über 80'000 Franken bei Online-Bank N26 geklau...  no_author   \n",
       "4  Der Wolf ist zurück – was auch Städter wissen ...  no_author   \n",
       "\n",
       "                              date nmbr_comments  \\\n",
       "0  28.03.19, 22:15 28.03.19, 22:40            19   \n",
       "1                          no_date   no_comments   \n",
       "2                 28.03.19, 17:39             29   \n",
       "3                 28.03.19, 17:34             18   \n",
       "4                 28.03.19, 16:19             45   \n",
       "\n",
       "                                              themes  \\\n",
       "0     ['Schweiz', 'Gesellschaft & Politik', 'Klima']   \n",
       "1                                                 []   \n",
       "2  ['Schweiz', 'Gesellschaft & Politik', 'Mobilit...   \n",
       "3  ['Digital', 'Schweiz', 'Datenschutz', 'Deutsch...   \n",
       "4   ['Schweiz', 'Wissen', 'Aargau', 'Natur', 'Tier']   \n",
       "\n",
       "                                             article  \n",
       "0  ['Naaa, wie kommt ihr so zur Uni? Mit dem Fahr...  \n",
       "1  ['\\r\\n\\t\\tMit deiner Anmeldung erklärst du dic...  \n",
       "2  ['\\nDer Ausbau des öffentlichen Verkehrs würde...  \n",
       "3  ['\\nDie gefeierte Online-Bank N26 verspielt ge...  \n",
       "4  ['\\nDer gesetzliche Schutz des Wolfes wird der...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>nmbr_comments</th>\n",
       "      <th>themes</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Jacqueline Büchi</th>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title  date  nmbr_comments  themes  article\n",
       "author                                                       \n",
       "Jacqueline Büchi    155   155            155     155      155"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv(\"watson_schweiz.csv\",sep = \";\") \n",
    "display(data.head(5))\n",
    "\n",
    "# filter no_author\n",
    "data = data[-data['author'].str.contains(\"no_author\")]\n",
    "\n",
    "# filter authors <50 articles - in order to make \n",
    "data = data.groupby('author')\n",
    "data = data.filter(lambda x: len(x) > 152).reset_index(drop = True)\n",
    "display(data.groupby('author').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to convert the string, which is actually a list, to a nice string.\n",
    "def listtostring(l):\n",
    "    import ast\n",
    "    list1 = ast.literal_eval(l)\n",
    "    list2 = \" \".join(list1)\n",
    "    list3 = list2.strip()\n",
    "    return list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = data[\"article\"].apply(listtostring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seit über 30 Jahren kämpft Christoph Blocher für eine Abschaffung der Sommerzeit. Nun könnte sein Wunsch in Erfüllung gehen – ausgerechnet dank seiner Erzfeindin, der EU.  Es war einmal, in den frühen 80er-Jahren, ein Zürcher Nationalrat. Er hiess Christoph Blocher und er hatte einen Traum: Die Sommerzeit sollte weg! Eilends lancierte er eine Volksinitiative. Allerdings brachten er und seine Mitstreiter der Zürcher SVP die nötigen Unterschriften nicht zusammen – das Vorhaben scheiterte im Sammelstadium. \\nChristoph Blocher anno 1980. Bild: KEYSTONE In den darauffolgenden Jahren verschob sich der Fokus Blochers. Sein Kampf galt nun der Unabhängigkeit der Schweiz von der Europäischen Union. Indem er sich erfolgreich gegen den Beitritt zum Europäischen Wirtschaftsraum (EWR) zur Wehr setzte, avancierte er 1992 zur Ikone aller EU-Skeptiker. Den Kampf gegen die Sommerzeit führten derweil andere für ihn weiter. Insbesondere Yvette Estermann, SVP-Nationalrätin aus dem Kanton Luzern. Erstmals forderte sie 2010 in einer Motion: \\n Der Bundesrat lehnte das Begehren ab, das Parlament ebenso. Doch Estermann gab nicht auf: 2012, 2016, 2017 und 2018 stiess sie mit mehreren ähnlich lautenden Vorstössen nach. \\nYvette Estermann liess nicht locker. Bild: KEYSTONE Der Bundesrat speiste die unermüdliche SVP-Frau jeweils mit der Antwort ab, die Schweiz halte an der Sommerzeit fest, weil sie sonst zur «Zeitinsel» in Europa würde. Diese Situation hatte man in den Sommermonaten im Jahr 1980 schon einmal, als die Eidgenossenschaft im Gegensatz zu den umliegenden Ländern noch keine Sommerzeit eingeführt hatte. Und die Erfahrungen, die man damit machte, waren alles andere als gut: Probleme im Transportwesen, im Tourismus und in der Kommunikation seien unvermeidlich, schreibt der Bundesrat in seinen Antworten auf Estermanns Vorstösse. Unter anderem wären «regelmässige Missverständnisse bei Terminen» zu erwarten, sollte die Schweiz zeittechnisch noch einmal auf diese Weise ausscheren. Nur falls «eine Mehrheit der die Schweiz umgebenden Länder» die Zeitumstellung abschaffen sollte, werde sich die Schweiz diesen Schritt auch überlegen, hielt der Bundesrat weiter fest. 6,783 \\n Dies dürfte mit dem heutigen Tag Realität werden. «Die Menschen wollen das, wir machen das», kündigte der EU-Kommissionspräsident Jean-Claude Juncker im ZDF-«Morgenmagazin» das Ende der Zeitumstellung an. Damit ist wohl auch in der Schweiz bald fertig an der Uhr gedreht. Die Ironie der Geschichte: Ausgerechnet die Europäische Union dürfte Christoph Blocher seinen langgehegten Traum erfüllen. Alle Gegener der Sommerzeitumstellung freuen sich! Endlich ein positiver Signal aus Brüssel... pic.twitter.com/5c0HLREaFJ \\n \\nVideo: srf Der Umbau in eine nachhaltige Wirtschaft schafft ideale Voraussetzungen für Unternehmer, Handwerker und Bauern. Was soll also der Krieg gegen vermeintliche «Klima-Kindersoldaten»? Nicolas Hayek war einer der bedeutendsten Schweizer Unternehmer in der zweiten Hälfte des letzten Jahrhunderts. Er hat die Uhrenindustrie gerettet und verschiedene Unternehmen saniert. In den Achtzigerjahren hatte Hayek eine Idee: Er wollte den Smart, ein Elektroauto für den Stadtverkehr, auf den Markt bringen.  Aus heutiger Sicht war Hayeks Idee visionär. Hätte er Erfolg gehabt, würde Tesla heute vielleicht nicht in der Wüste von Nevada, sondern im Berner Seeland gefertigt. Hayek zerbrach am …'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer object\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=None,\n",
    "                                              filters = '#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "                                              lower = False,\n",
    "                                              split = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train tokenizer to text\n",
    "tokenizer.fit_on_texts(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "\n",
    "training_length = 50\n",
    "\n",
    "# Iterate through the sequences of tokens\n",
    "for seq in sequences:\n",
    "\n",
    "    # Create multiple training examples from each sequence\n",
    "    for i in range(training_length, len(seq)):\n",
    "        \n",
    "        # Extract the features and label\n",
    "        extract = seq[i - training_length:i + 1]\n",
    "\n",
    "        # Set the features and label\n",
    "        features.append(extract[:-1])\n",
    "        labels.append(extract[-1])\n",
    "        \n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27597"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(137474, 27597)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of words in vocabulary\n",
    "num_words = len(tokenizer.index_word)+1\n",
    "\n",
    "display(num_words)\n",
    "\n",
    "# empty array for labels\n",
    "label_array = np.zeros((len(features), num_words),dtype = np.int8)\n",
    "\n",
    "# one hot encode labels\n",
    "for example_index, word, in enumerate(labels):\n",
    "    label_array[example_index, word]= 1\n",
    "    \n",
    "label_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gzip\n",
    "# import shutil\n",
    "# with gzip.open(r'C:\\Users\\gwehrm\\Downloads\\cc.de.300.vec.gz', 'rb') as f_in:\n",
    "#     with open(r'C:\\Users\\gwehrm\\Documents\\Repos\\watson_analysis\\german_emb.txt', 'wb') as f_out:\n",
    "#         shutil.copyfileobj(f_in, f_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Word2VecVocab' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-a651ea47f43f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_watson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Word2VecVocab' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "model_watson.vocabulary[\".\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-f4ee7ca884ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Create lookup of words to vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mword_lookup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvector\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvector\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# New matrix to hold word embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "# load a pretrained model to get the word embeddings\n",
    "model_watson = Word2Vec.load(\"word2vec.model_watson\")\n",
    "\n",
    "model_watson.vector_size\n",
    "\n",
    "\n",
    "# New matrix to hold word embeddings\n",
    "embedding_matrix = np.zeros((num_words, vectors.shape[1]))\n",
    "\n",
    "for i, word in enumerate(word_idx.keys()):\n",
    "    # Look up the word embedding\n",
    "    vector = word_lookup.get(word, None)\n",
    "\n",
    "    # Record in matrix\n",
    "    if vector is not None:\n",
    "        embedding_matrix[i + 1, :] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build RNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "model.add(\n",
    "    Embedding(input_dim=num_words,\n",
    "              input_length = training_length,\n",
    "              output_dim=100,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False,\n",
    "              mask_zero=True))\n",
    "\n",
    "# Masking layer for pre-trained embeddings\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "# Recurrent layer\n",
    "model.add(LSTM(64, return_sequences=False, \n",
    "               dropout=0.1, recurrent_dropout=0.1))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Dropout for regularization\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(num_words, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
